
# Konpeki üíé - Assistente de IA Pessoal

Konpeki (Á¥∫Á¢ß, "azul-celeste profundo") √© um projeto de assistente de IA que roda localmente, garantindo total privacidade dos dados e sem custos de API. Ele utiliza um modelo de linguagem de c√≥digo aberto (LLM) atrav√©s do Ollama e apresenta uma interface de chat amig√°vel constru√≠da com Streamlit.

## ‚ú® Funcionalidades

- **Interface de Chat Interativa:** Uma interface web simples e intuitiva para conversar com a IA.
- **Respostas em Tempo Real:** As respostas da IA s√£o exibidas palavra por palavra (streaming), proporcionando uma experi√™ncia din√¢mica.
- **Personalidade Definida:** A IA possui uma identidade predefinida ("Konpeki") atrav√©s de um prompt de sistema, que pode ser customizado.
- **Gerenciamento de Hist√≥rico:** O hist√≥rico da conversa √© mantido durante a sess√£o e pode ser limpo atrav√©s de um bot√£o na barra lateral.
- **100% Local e Privado:** Utiliza o Ollama para rodar o modelo de linguagem na sua pr√≥pria m√°quina. Nenhuma informa√ß√£o √© enviada para servi√ßos de terceiros.

## üõ†Ô∏è Tecnologias Utilizadas

- **Python 3.10+**
- **Streamlit:** Para a cria√ß√£o da interface web.
- **LangChain:** Como framework para orquestrar a l√≥gica do agente de IA.
- **Ollama:** Para servir o modelo de linguagem de c√≥digo aberto localmente.
- **Llama 3:** O modelo de linguagem (LLM) que atua como o "c√©rebro" da Konpeki.

---

## üöÄ Guia de Instala√ß√£o e Execu√ß√£o

Siga estes passos para configurar e rodar o projeto na sua m√°quina.

### Pr√©-requisitos

Antes de come√ßar, garanta que voc√™ tenha os seguintes softwares instalados:

1.  **Python:** [Instale a partir do site oficial](https://www.python.org/downloads/).
2.  **Ollama:** [Instale a partir do site oficial](https://ollama.com/).

### Passo 1: Baixar o Modelo de Linguagem

Ap√≥s instalar o Ollama, abra o seu terminal e rode o seguinte comando para baixar o modelo Llama 3. Este passo pode demorar um pouco dependendo da sua conex√£o com a internet.

```bash
ollama pull llama3
```

*Opcional: Ap√≥s o download, voc√™ pode rodar `ollama run llama3` no terminal para ter uma primeira conversa com o modelo puro e garantir que ele est√° funcionando.*

### Passo 2: Configurar o Ambiente do Projeto

1.  **Navegue at√© a pasta do projeto:**
    ```bash
    cd caminho/para/agente-ia-konpeki
    ```

2.  **(Recomendado) Crie e ative um ambiente virtual:**
    Isso isola as depend√™ncias do projeto e evita conflitos.
    ```bash
    # Criar o ambiente
    python3 -m venv venv

    # Ativar no Linux/macOS
    source venv/bin/activate

    # Ativar no Windows
    .\venv\Scripts\activate
    ```

3.  **Instale as bibliotecas Python necess√°rias:**
    ```bash
    pip install -r requirements.txt
    ```

### Passo 3: Executar a Aplica√ß√£o

Com o ambiente virtual ativado e as depend√™ncias instaladas, inicie a aplica√ß√£o Streamlit com o comando:

```bash
streamlit run app.py
```

Uma nova aba deve abrir automaticamente no seu navegador, exibindo a interface de chat da Konpeki. Se n√£o abrir, o terminal mostrar√° um endere√ßo local (ex: `http://localhost:8501`) que voc√™ pode abrir manualmente.

**Importante:** O servidor do Ollama precisa estar em execu√ß√£o para que o `app.py` funcione. Normalmente, o Ollama roda em segundo plano ap√≥s a instala√ß√£o. Se a aplica√ß√£o mostrar um erro de conex√£o, certifique-se de que o aplicativo do Ollama est√° aberto.

---

## üß† Como Funciona?

- **Frontend (Streamlit):** O arquivo `app.py` usa a biblioteca Streamlit para desenhar a interface de chat, incluindo a barra lateral, os avatares e as mensagens.
- **L√≥gica de Chat (LangChain):** A biblioteca LangChain √© usada para estruturar a conversa. Ela gerencia o hist√≥rico de mensagens (incluindo o prompt de sistema secreto que define a personalidade) e se comunica com o modelo de linguagem.
- **"C√©rebro" (Ollama + Llama 3):** Quando voc√™ envia uma pergunta, o LangChain a envia para o servidor Ollama, que por sua vez a processa com o modelo Llama 3 e devolve a resposta. Todo esse processo acontece na sua m√°quina.

## üîÆ Pr√≥ximos Passos

A pr√≥xima grande melhoria para a Konpeki √© dar a ela conhecimento sobre seus pr√≥prios dados. Isso √© feito atrav√©s de uma t√©cnica chamada **RAG (Retrieval-Augmented Generation)**, que permite que a IA consulte seus documentos (PDFs, TXTs, etc.) para formular respostas.
